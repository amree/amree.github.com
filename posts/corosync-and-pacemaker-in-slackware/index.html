<!doctype html><html lang=en><head><title>Corosync and Pacemaker in Slackware :: Amree Zaid</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This will be multi part post about high availability solution for Slackware. My first post will be about Corosync and Pacemaker.
You need to combine Corosync and Pacemaker with other distributed storage system such as DRBD/OCFS2/GFS. I&amp;rsquo;ll talk about these stacks in another post.
"><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://amree.github.io/posts/corosync-and-pacemaker-in-slackware/><link rel=stylesheet href=https://amree.github.io/assets/style.css><link rel=stylesheet href=https://amree.github.io/assets/green.css><link rel=apple-touch-icon href=https://amree.github.io/img/apple-touch-icon-192x192.png><link rel="shortcut icon" href=https://amree.github.io/img/favicon/green.png><meta name=twitter:card content="summary"><meta name=twitter:site content><meta name=twitter:creator content><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="Corosync and Pacemaker in Slackware"><meta property="og:description" content="This will be multi part post about high availability solution for Slackware. My first post will be about Corosync and Pacemaker.
You need to combine Corosync and Pacemaker with other distributed storage system such as DRBD/OCFS2/GFS. I&amp;rsquo;ll talk about these stacks in another post.
"><meta property="og:url" content="https://amree.github.io/posts/corosync-and-pacemaker-in-slackware/"><meta property="og:site_name" content="Amree Zaid"><meta property="og:image" content="https://amree.github.io/img/favicon/green.png"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2012-05-14 00:00:00 +0000 UTC"></head><body class=green><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>Amree Zaid</div></a></div><div class=menu-trigger>menu</div></div><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=https://twitter.com/AmreeZaid>Twitter</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=https://twitter.com/AmreeZaid>Twitter</a></li></ul></nav></header><div class=content><div class=post><h1 class=post-title><a href=https://amree.github.io/posts/corosync-and-pacemaker-in-slackware/>Corosync and Pacemaker in Slackware</a></h1><div class=post-meta><span class=post-date>2012-05-14</span></div><span class=post-tags>#<a href=https://amree.github.io/tags/linux/>linux</a>&nbsp;</span><div class=post-content><div><p>This will be multi part post about high availability solution for Slackware. My
first post will be about Corosync and Pacemaker.</p><p>You need to combine Corosync and Pacemaker with other distributed storage system
such as
<a href=http://www.drbd.org/>DRBD</a>/<a href=http://oss.oracle.com/projects/ocfs2/>OCFS2</a>/<a href=http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/5/html-single/Global_File_System_2/>GFS</a>. I&rsquo;ll talk about these stacks in another post.</p><p>GOAL:</p><ul><li>A MySQL server will always be available at the same IP even though it&rsquo;s
actually down (another server will take over automatically without the needs
for manual intervention).</li></ul><p>Environments:</p><ul><li><p>Slackware v13.37</p></li><li><p>Two nodes will be used:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>Node 1:
192.168.1.101

Node 2:
192.168.1.102

Cluster/Main/Failover IP:
192.168.1.100
</code></pre></div></li></ul><p>The MySQL data is not syncronized, this post is just about
<a href=http://www.corosync.org/>Corosync</a> and <a href=http://www.clusterlabs.org/>Pacemaker</a>.</p><p>Guides:</p><ol><li><p>Download and install these packages (by this order) in both nodes:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>http://slackbuilds.org/repository/13.37/libraries/libnet/
http://slackbuilds.org/repository/13.37/libraries/libesmtp/
http://slackbuilds.org/repository/13.37/system/clusterglue/
http://slackbuilds.org/repository/13.37/system/clusterresourceagents/
http://slackbuilds.org/repository/13.37/system/corosync/
http://slackbuilds.org/repository/13.37/system/pacemaker/
</code></pre></div><p>I strongly suggest you build these packages one by one just to be sure there
are no missing dependencies. BTW, some script adjustments are needed for
Cluster Resource Agents but I&rsquo;m sure you guys can handle it ;-)</p></li><li><p>It would be easier for the next steps if
<a href=http://www.debian-administration.org/articles/152>password-less</a> login with
OpenSSH is enabled. In your <code>Node 1</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh-keygen -t rsa
ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.102
</code></pre></div></li><li><p>Generate an authentication key for Corosync:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>corosync-keygen
</code></pre></div><p>If you&rsquo;re connecting remotely, pressing your keyboard won&rsquo;t do any good. The
fastest way would be typing directly into the server. The other way is
running <code>find .</code> on your <code>/</code> directory (press <code>Control + C</code> when the key has
been generated).</p></li><li><p>Copy the new generated authentication key to <code>Node 2</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp /etc/corosync/authkey 192.168.1.102:/etc/corosync
</code></pre></div></li><li><p>Copy the default <code>corosync</code> configuration file:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cp /etc/corosync/corosync.conf.example /etc/corosync/corosync.conf
</code></pre></div></li><li><p>Replace <code>bindnetaddr</code> and <code>logfile</code> (optional):</p><pre><code>bindnetaddr: 192.168.1.0
logfile: /var/log/corosync
</code></pre><p>You can checkout the <a href="http://www.corosync.org/doku.php?id=faq:configure_openais">reference</a> about those values. From corosync:</p><blockquote><p>If the local interface was 10.12.12.93 and the netmask was 255.0.0.0, Totem
would execute the logical operation 10.12.12.93 & 255.0.0.0 and produce the
value 10.0.0.0. This value would be compared against bindnetaddr and bind Totem
to the NIC that matches. This can cause confusion if netmask or bindnetaddr are
not set properly. In the example above, if bindnetaddr is 10.12.12.0, the
network interface will never be matched. If bindnetaddr is 10.0.0.0 the
interface will be matched.</p></blockquote></li><li><p>Copy <code>corosync.conf</code> to <code>Node 2</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp /etc/corosync/corosync.conf 192.168.1.102:/etc/corosync
</code></pre></div></li><li><p>Create <code>pacemaker</code> file so that <code>Corosync</code> will automatically load <code>Pacemaker</code> when it&rsquo;s started:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>touch /etc/corosync/service.d/pacemaker
</code></pre></div><p>Put these configs in that file:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>service {
  # Load the Pacemaker Cluster Resource Manager
  name: pacemaker
  ver:  0
}
</code></pre></div></li><li><p>Copy the <code>pacemaker</code> file to Node 2:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp /etc/corosync/service.d/pacemaker 192.168.1.102:/etc/corosync/service.d/
</code></pre></div></li><li><p>Start your Corosync and let the magic begins:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>/etc/rc.d/rc.corosync start
</code></pre></div></li><li><p>Check your log for any error:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tail -f /var/log/corosync
</code></pre></div><p>Check your process list:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ps auxf
</code></pre></div><p>Corosync should also load other processes automatically:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>root      2008  0.5  3.4  52668  3964 ?        Ssl  13:55   0:00 corosync
root      2015  0.0  1.9  12140  2248 ?        S    13:55   0:00  \_ /usr/lib/heartbeat/stonithd
226       2016  0.3  3.3  13004  3796 ?        S    13:55   0:00  \_ /usr/lib/heartbeat/cib
root      2017  0.0  1.6   6812  1848 ?        S    13:55   0:00  \_ /usr/lib/heartbeat/lrmd
226       2018  0.1  2.2  12404  2540 ?        S    13:55   0:00  \_ /usr/lib/heartbeat/attrd
226       2019  0.0  1.7   8664  2032 ?        S    13:55   0:00  \_ /usr/lib/heartbeat/pengine
226       2020  0.1  2.5  12528  2904 ?        S    13:55   0:00  \_ /usr/lib/heartbeat/crmd
</code></pre></div></li><li><p>Monitor your cluster using Pacemaker tools:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm status
</code></pre></div><p>It should be something like this:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#f92672>============</span>
Last updated: Sun May <span style=color:#ae81ff>13</span> 13:57:43 <span style=color:#ae81ff>2012</span>
Stack: openais
Current DC: node1 - partition with quorum
Version: 1.1.1-b9b672590e79770afb63b9b455400d92fb6b5d9e
<span style=color:#ae81ff>2</span> Nodes configured, <span style=color:#ae81ff>2</span> expected votes
<span style=color:#ae81ff>0</span> Resources configured.
<span style=color:#f92672>============</span>

Online: <span style=color:#f92672>[</span> node1 node2 <span style=color:#f92672>]</span>
</code></pre></div><p>Give them some time to online if they&rsquo;re offline.</p></li><li><p>Put some main configurations to your cluster:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm
configure
property stonith-enabled<span style=color:#f92672>=</span>false
property no-quorum-policy<span style=color:#f92672>=</span>ignore
commit
quit
</code></pre></div><p>If you&rsquo;re getting some errors such as <code>ERROR: cib-bootstrap-options: attribute last-lrm-refresh does not exist</code>, just proceed. It maybe a
<a href=http://www.gossamer-threads.com/lists/linuxha/users/63183>bug</a>.</p><p>We had to disable <code>stonith</code> since we just want our Pacemaker to be running.
However, in real production environment, you really need to configure
<code>stonith</code>, you can read more about it
<a href="http://www.novell.com/support/kb/doc.php?id=7004817">here</a>.</p><p>We also need to ignore quorum policy since we&rsquo;re only using 2 nodes and you
can read more about it
<a href=http://www.clusterlabs.org/wiki/FAQ#I_Killed_a_Node_but_the_Cluster_Didn.27t_Recover>here</a>.</p><p>You can see your new configuration by running:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm configure show
</code></pre></div><p>Which will output:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>node node1
node node2
property $id=&#34;cib-bootstrap-options&#34; \
    dc-version=&#34;1.1.1-b9b672590e79770afb63b9b455400d92fb6b5d9e&#34; \
    cluster-infrastructure=&#34;openais&#34; \
    expected-quorum-votes=&#34;2&#34; \
    stonith-enabled=&#34;false&#34; \
    last-lrm-refresh=&#34;1336919205&#34; \
    no-quorum-policy=&#34;ignore&#34;
</code></pre></div><p>If you accidentally put some wrong configurations and don&rsquo;t know how to edit
it, you can use <code>crm configure edit</code> to change your configurations directly
but this method is highly not recommended since it&rsquo;s error-prone.</p></li><li><p>It&rsquo;s time to configure our main/failover/cluster IP (our client will use
this IP, not the nodes IP):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm
configure
primitive ip ocf:heartbeat:IPaddr params ip<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;192.168.1.100&#34;</span> op monitor interval<span style=color:#f92672>=</span>10s
commit
</code></pre></div></li><li><p>If everyting goes well, you should be able to ping the cluster IP (<code>192.168.1.100</code>) and <code>crm status</code> should yield this result:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>============
Last updated: Sun May 13 14:28:19 2012
Stack: openais
Current DC: node1 - partition with quorum
Version: 1.1.1-b9b672590e79770afb63b9b455400d92fb6b5d9e
2 Nodes configured, 2 expected votes
1 Resources configured.
============

Online: [ node1 node2 ]

ip     (ocf::heartbeat:IPaddr):        Started node1
</code></pre></div></li><li><p>We&rsquo;ll now setup MySQL monitoring with <code>Pacemaker</code>. But before that, make sure you:</p><p>Installed MySQL in both of the nodes.</p><p>Able to connect to your MySQL from other than <code>localhost</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mysql -u root -p -h 192.168.1.101
mysql -u root -p -h 192.168.1.102
</code></pre></div><p>You can use this command to allow any host to connect to your MySQL:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;password&#39; WITH GRANT OPTION;
FLUSH PRIVILEGES;
</code></pre></div><p>Created a database in <code>Node 1</code> and <code>Node 2</code>. For an example, a database
named <code>node1</code> in <code>Node 1</code> and <code>node2</code> in <code>Node 2</code>. This is just for
verification.</p></li><li><p>Add this resource:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm
configure
primitive mysql ocf:heartbeat:mysql <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>params binary<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/usr/bin/mysqld_safe&#34;</span> config<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/etc/my.cnf&#34;</span> user<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;mysql&#34;</span> pid<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/var/run/mysql/mysql.pid&#34;</span> datadir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/var/lib/mysql&#34;</span> socket<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/var/run/mysql/mysql.sock&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>op monitor interval<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;30s&#34;</span> timeout<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;30s&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>op start interval<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0&#34;</span> timeout<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;120&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>op stop interval<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0&#34;</span> timeout<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;120&#34;</span>
commit
quit
</code></pre></div><p>The parameter above is purely based on the standard Slackware&rsquo;s MySQL
package. So make sure you&rsquo;ve created <code>/etc/my.cnf</code> which is not available by
default. Just copy from the default file:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cp /etc/my-small.cnf /etc/my.cnf
</code></pre></div></li><li><p>Your latest <code>crm status</code> would show something like this:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>============
Last updated: Mon May 14 01:13:23 2012
Stack: openais
Current DC: node1 - partition with quorum
Version: 1.1.1-b9b672590e79770afb63b9b455400d92fb6b5d9e
2 Nodes configured, 2 expected votes
2 Resources configured.
============

Online: [ node1 node2 ]

 ip (ocf::heartbeat:IPaddr):    Started node1
 mysql  (ocf::heartbeat:mysql): Started node2
</code></pre></div><p>As you can see, <code>mysql</code> has been started on <code>Node 2</code>. Actually it doesn&rsquo;t
matter in which node it will start first (for this tutorial, not for the
production server), what important is that if one of the nodes is down, the
other node should start its MySQL automatically. You can test this situation
by running these commands in your <code>Node 2</code> to simulate a node failure:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm
node
standby
quit
</code></pre></div><p><code>crm status</code> would show something like this (give <code>Node 1</code> some time before it starts its MySQL):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>============
Last updated: Mon May 14 01:21:12 2012
Stack: openais
Current DC: node1 - partition with quorum
Version: 1.1.1-b9b672590e79770afb63b9b455400d92fb6b5d9e
2 Nodes configured, 2 expected votes
2 Resources configured.
============

Node node2: standby
Online: [ node1 ]

 ip (ocf::heartbeat:IPaddr):    Started node1
 mysql  (ocf::heartbeat:mysql): Started node1
</code></pre></div><p>Right now, your client can use the cluster IP (<code>192.168.1.100</code>) to connect
to your MySQL. The client won&rsquo;t realize which node it connected to. In this
case, he/she will connect to <code>Node 2</code> if both of them (the nodes) are
online. If <code>Node 2</code> is offline, <code>192.168.1.100</code> will automatically connect
the client to MySQL in <code>192.168.1.101</code>. If <code>Node 1</code> is offline,
<code>192.168.1.100</code> will automatically uses MySQL in <code>Node 2</code> which is in
<code>192.168.1.102</code>.</p><p>To reonline <code>Node 2</code>, just use these commands in your <code>Node 2</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm
node
online
quit
</code></pre></div></li><li><p>However, usually you want to control which MySQL will be up first, either in
<code>Node 1</code> or in <code>Node 2</code>. To make this happen, you need to use <code>colocation</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crm
configure
colocation ip-mysql inf: ip mysql
commit
quit
</code></pre></div><p><code>crm status</code> would show something like this:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt>============
Last updated: Mon May 14 01:26:41 2012
Stack: openais
Current DC: node1 - partition with quorum
Version: 1.1.1-b9b672590e79770afb63b9b455400d92fb6b5d9e
2 Nodes configured, 2 expected votes
2 Resources configured.
============

Online: [ node1 node2 ]

 ip (ocf::heartbeat:IPaddr):    Started node1
 mysql  (ocf::heartbeat:mysql): Started node1
</code></pre></div><p>That means, your <code>mysql</code> has been started on <code>Node 1</code>. So, everytime
<code>corosync</code> is started on both of the nodes, <code>mysql</code> will be started on <code>Node 1</code> due to the <code>colocation</code> configuration.</p></li><li><p>Try turning off <code>Node 1</code> or <code>Node 2</code> and see how MySQL switches side from both of the nodes.</p></li></ol><p>I think that&rsquo;s it, next tutorial should be mainly about DRBD. Good luck!</p></div></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://amree.github.io/posts/getting-started-with-xen-on-slackware/><span class=button__icon>←</span>
<span class=button__text>Getting Started with Xen on Slackware</span></a></span>
<span class="button next"><a href=https://amree.github.io/posts/using-grub-instead-of-lilo-in-slackware/><span class=button__text>Using GRUB instead of LILO in Slackware</span>
<span class=button__icon>→</span></a></span></div></div></div></div><footer class=footer><div class=footer__inner><div class=copyright><span>© 2021 Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>:: Theme made by <a href=https://twitter.com/panr>panr</a></span></div></div></footer><script src=https://amree.github.io/assets/main.js></script><script src=https://amree.github.io/assets/prism.js></script></div></body></html>